# 1. Imports essenciais
import streamlit as st
import os
import google.generativeai as genai
from dotenv import load_dotenv

# 2. ConfiguraÃ§Ã£o da PÃ¡gina (Aba do Navegador)
st.set_page_config(
    page_title="Argos IA - AnÃ¡lise de CÃ³digo",
    page_icon="ğŸ›¡ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# 3. Carregamento e VerificaÃ§Ã£o da API Key
load_dotenv()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

if not GEMINI_API_KEY:
    st.error("ğŸ”‘ Chave da API do Gemini nÃ£o encontrada. Verifique seu arquivo .env.")
    st.stop()

# 4. ConfiguraÃ§Ã£o da API do Gemini
genai.configure(api_key=GEMINI_API_KEY)

# FunÃ§Ã£o para inicializar o modelo
def init_gemini():
    generation_config = {
        "temperature": 0.7,
        "top_p": 0.8,
        "top_k": 40,
        "max_output_tokens": 2048,
    }
    
    model = genai.GenerativeModel(
        model_name="gemini-1.5-flash",
        generation_config=generation_config
    )
    return model

# FunÃ§Ã£o para gerar resposta do chatbot, incorporando a persona "Argos IA"
def generate_response(model, user_prompt):
    # Prompt do sistema que instrui o modelo a agir como o Argos IA
    system_prompt = """
    VocÃª Ã© o Argos IA, um assistente de engenharia de software especializado em anÃ¡lise de cÃ³digo.
    Sua tarefa Ã© receber um trecho de cÃ³digo e retornar uma anÃ¡lise estruturada, clara e acionÃ¡vel.
    Sua resposta DEVE ser em formato Markdown e seguir estritamente as seguintes seÃ§Ãµes:

    ### ğŸ“ Resumo de Alto NÃ­vel
    (Descreva em linguagem natural e de forma concisa o que o cÃ³digo faz.)

    ### ğŸ¯ Principais Responsabilidades
    (Liste em bullet points as aÃ§Ãµes e lÃ³gicas especÃ­ficas que o cÃ³digo executa.)

    ### ğŸ” Insights e Pontos de AtenÃ§Ã£o
    (Destaque pontos crÃ­ticos que um revisor humano procuraria. Use emojis para categorizar. Exemplos:)
    - âš ï¸ **Risco de SeguranÃ§a:** (Se houver uma vulnerabilidade clara.)
    - âš™ï¸ **SugestÃ£o de RefatoraÃ§Ã£o:** (Se o cÃ³digo puder ser mais limpo, eficiente ou menos complexo.)
    - ğŸ”— **DependÃªncia Externa:** (Se o cÃ³digo interage com APIs, bancos de dados, etc.)
    - ğŸ’¡ **Oportunidade de Melhoria:** (Qualquer outra sugestÃ£o para melhorar o cÃ³digo.)

    Analise o seguinte cÃ³digo:
    """
    
    # Combina o prompt do sistema com a entrada do usuÃ¡rio
    full_prompt = f"{system_prompt}\n```\n{user_prompt}\n```"

    try:
        response = model.generate_content(full_prompt)
        return response.text
    except Exception as e:
        return f"Erro ao gerar resposta: {str(e)}"

# --- Interface do UsuÃ¡rio ---

# ConfiguraÃ§Ã£o da sidebar
with st.sidebar:
    st.header("âš™ï¸ Controles")
    if st.button("ğŸ—‘ï¸ Limpar Conversa"):
        st.session_state.messages = []
        st.rerun()
    st.divider()
    st.subheader("ğŸ“Š EstatÃ­sticas")
    st.metric("Mensagens trocadas", len(st.session_state.get('messages', [])))

# InicializaÃ§Ã£o do modelo na sessÃ£o
if 'model' not in st.session_state:
    with st.spinner("ğŸ”„ Inicializando o Argos IA..."):
        st.session_state.model = init_gemini()

# TÃ­tulo e descriÃ§Ã£o principal
st.image("https://i.imgur.com/8a2eY4v.png", width=100) # Exemplo de logo, pode ser removido
st.title("ğŸ›¡ï¸ Argos IA")
st.write("Seu assistente para anÃ¡lise e revisÃ£o de cÃ³digo. Cole um trecho de cÃ³digo abaixo para receber insights.")

# InicializaÃ§Ã£o do histÃ³rico de mensagens
if 'messages' not in st.session_state:
    st.session_state.messages = []
    # Mensagem de boas-vindas do Argos
    st.session_state.messages.append({
        "role": "assistant",
        "content": """ğŸ‘‹ OlÃ¡! Eu sou o Argos IA. 
        
Estou pronto para analisar seu cÃ³digo. Cole uma funÃ§Ã£o, classe ou script no campo abaixo e eu fornecerei um resumo estruturado com responsabilidades e pontos de atenÃ§Ã£o."""
    })

# ExibiÃ§Ã£o do histÃ³rico de mensagens
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Input do usuÃ¡rio
if prompt := st.chat_input("Cole seu cÃ³digo aqui..."):
    # Adicionar mensagem do usuÃ¡rio ao histÃ³rico e Ã  tela
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(f"```\n{prompt}\n```")
    
    # Gerar e exibir resposta do assistente
    with st.chat_message("assistant"):
        with st.spinner("ğŸ” Analisando o cÃ³digo..."):
            response = generate_response(st.session_state.model, prompt)
            st.markdown(response)
    
    # Adicionar resposta do assistente ao histÃ³rico
    st.session_state.messages.append({"role": "assistant", "content": response})